# ğŸ›ï¸ Legal RAG System - Turkish Legal Documents

A comprehensive Retrieval-Augmented Generation (RAG) system for Turkish legal documents, featuring semantic search, law type classification, and intelligent chunking.

## ğŸ“‹ Overview

This RAG system processes and provides intelligent search capabilities for Turkish legal documents including:
- **Ä°klim Kanunu** (Climate Law)
- **Siber GÃ¼venlik Kanunu** (Cyber Security Law)  
- **Ticaret Kanunu** (Trade Law)
- **Ceza Kanunu** (Criminal Law)
- And many more...

### ğŸ¯ Key Features

- **ğŸ” Semantic Search**: Find relevant content using natural language queries
- **ğŸ“Š Law Type Classification**: Automatic categorization into 16+ law types
- **ğŸ§© Intelligent Chunking**: Article-level and section-level text segments
- **ğŸŒ Multilingual Support**: Optimized for Turkish legal terminology
- **ğŸ“ˆ Performance Analytics**: Search logging and performance tracking
- **ğŸ”Œ Multiple Embedding Options**: SentenceTransformers, OpenAI, TF-IDF

## ğŸ—‚ï¸ Dataset Structure

### Enhanced Metadata Dataset
- **1,570 laws** with rich metadata
- **16 law categories** automatically classified
- **Full text** with structured information
- **Section extraction** and article counting

### Chunked RAG Dataset  
- **1,854 optimized chunks** for retrieval
- **Article-level granularity** where possible
- **Contextual metadata** preserved in each chunk
- **Perfect for** vector embeddings and semantic search

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Install core dependencies
pip install pandas numpy sqlite3

# For best performance (recommended)
pip install sentence-transformers torch transformers

# Alternative: TF-IDF (lightweight)
pip install scikit-learn

# Optional: OpenAI embeddings
pip install openai

# Complete requirements
pip install -r requirements_rag.txt
```

### 2. Create Enhanced Dataset

```bash
# Process original legal documents
python create_enhanced_dataset.py
```

This creates:
- `mevzuat_enhanced_dataset.csv` - Laws with metadata
- `mevzuat_chunked_for_rag.csv` - Chunks for RAG

### 3. Build Vector Database

```bash
# Build the complete RAG system
python build_vector_database.py
```

This will:
- âœ… Create SQLite database
- ğŸ“¡ Load multilingual embedding model  
- ğŸ”„ Generate embeddings for all chunks
- ğŸ’¾ Save model configuration

### 4. Query the System

```bash
# Interactive mode
python query_legal_rag.py

# Single search
python query_legal_rag.py --search "iklim deÄŸiÅŸikliÄŸi"

# Show statistics
python query_legal_rag.py --stats
```

## ğŸ’» Usage Examples

### Interactive Query Interface

```python
from build_vector_database import LegalRAGDatabase

# Initialize system
rag = LegalRAGDatabase("mevzat_rag.db")

# Semantic search
results = rag.search("karbon emisyonu azaltÄ±mÄ±", top_k=5)

for result in results:
    print(f"Law: {result['law_name']}")
    print(f"Type: {result['law_type']}")
    print(f"Score: {result['similarity_score']:.3f}")
    print(f"Text: {result['text'][:200]}...")
    print("-" * 50)
```

### Filtered Search

```python
# Search only in environmental laws
results = rag.search(
    query="sera gazÄ±", 
    top_k=3,
    law_type_filter="Ã‡evre ve Ä°klim"
)

# Search only in articles (not sections)
results = rag.search(
    query="ceza hÃ¼kÃ¼mleri",
    chunk_type_filter="article"
)
```

### Get Law Information

```python
# Get detailed law metadata
law_info = rag.get_law_metadata("Ä°KLÄ°M KANUNU")
print(f"Articles: {law_info['article_count']}")
print(f"Word count: {law_info['word_count']:,}")
print(f"Sections: {law_info['sections']}")
```

## ğŸ”§ Configuration Options

### Embedding Models

#### 1. SentenceTransformers (Recommended)
```python
rag.load_embedding_model(
    "sentence_transformer", 
    "paraphrase-multilingual-MiniLM-L12-v2"
)
```

#### 2. OpenAI Embeddings
```python
import openai
openai.api_key = "your-api-key"

rag.load_embedding_model("openai", "text-embedding-ada-002")
```

#### 3. TF-IDF (Lightweight)
```python
rag.load_embedding_model("tfidf")
```

### Database Schema

```sql
-- Chunks table
CREATE TABLE chunks (
    chunk_id TEXT PRIMARY KEY,
    law_name TEXT,
    law_type TEXT,
    chunk_type TEXT,  -- 'article' or 'section'
    chunk_index INTEGER,
    text TEXT,
    char_count INTEGER,
    word_count INTEGER,
    embedding BLOB,    -- Pickled numpy array
    created_at TIMESTAMP
);

-- Laws metadata table
CREATE TABLE laws_metadata (
    law_id TEXT PRIMARY KEY,
    law_name TEXT,
    law_type TEXT,
    full_text TEXT,
    sections TEXT,     -- JSON array
    article_count INTEGER,
    character_count INTEGER,
    word_count INTEGER,
    processing_date TEXT
);
```

## ğŸ¯ Law Type Categories

The system automatically classifies laws into these categories:

1. **Ã‡evre ve Ä°klim** - Environment & Climate
2. **Teknoloji ve Siber GÃ¼venlik** - Technology & Cyber Security  
3. **Ticaret Kanunu** - Trade Law
4. **Ä°ÅŸ ve Sosyal GÃ¼venlik** - Labor & Social Security
5. **Ceza Kanunu** - Criminal Law
6. **Medeni Kanun** - Civil Law
7. **Ä°dare Kanunu** - Administrative Law
8. **Vergi Kanunu** - Tax Law
9. **SaÄŸlÄ±k** - Health
10. **EÄŸitim** - Education
11. **UlaÅŸtÄ±rma** - Transportation
12. **TarÄ±m** - Agriculture
13. **Enerji** - Energy
14. **BankacÄ±lÄ±k ve Finans** - Banking & Finance
15. **Ä°nsan HaklarÄ±** - Human Rights
16. **Anayasa** - Constitutional Law

## ğŸ“Š Performance & Statistics

### Search Performance
- **Semantic Search**: ~0.1-0.5 seconds per query
- **Text Search**: ~0.05-0.1 seconds per query
- **Database Size**: ~50MB (with embeddings)

### Dataset Statistics
```
Total Laws: 1,570
Total Chunks: 1,854
Average Chunks per Law: 1.2
Top Law Types:
  - Ticaret Kanunu: 681 chunks
  - Ä°ÅŸ ve Sosyal GÃ¼venlik: 390 chunks
  - Ä°dare Kanunu: 116 chunks
```

## ğŸ” Interactive Commands

The query interface supports these commands:

```bash
search <query>          # Text-based search
vsearch <query>         # Vector/semantic search  
types                   # List available law types
laws [type]            # List laws (optionally by type)
info <law_name>        # Get detailed law information
browse <law_type>      # Browse chunks by law type
stats                  # Show database statistics
help                   # Show help
exit                   # Exit program
```

## ğŸ› ï¸ Advanced Usage

### Batch Processing

```python
# Process multiple queries
queries = [
    "iklim deÄŸiÅŸikliÄŸi",
    "siber saldÄ±rÄ±", 
    "Ã§evre koruma",
    "veri gÃ¼venliÄŸi"
]

for query in queries:
    results = rag.search(query, top_k=3)
    print(f"\n=== {query} ===")
    for r in results:
        print(f"{r['law_name']}: {r['similarity_score']:.3f}")
```

### Custom Chunking

```python
# Modify chunking parameters
chunks = chunk_law_text(
    text=law_text,
    law_name="Custom Law", 
    law_type="Custom Type",
    chunk_size=2000  # Larger chunks
)
```

### Export Results

```python
import pandas as pd

# Search and export to CSV
results = rag.search("karbon ticareti", top_k=20)
df = pd.DataFrame(results)
df.to_csv("search_results.csv", index=False)
```

## ğŸ”® Future Enhancements

- **ğŸ¤– Integration with LLMs** (GPT, Claude, Llama)
- **ğŸŒ Web Interface** (Streamlit/FastAPI)
- **ğŸ“± Mobile App** support
- **ğŸ”„ Real-time Updates** as new laws are published
- **ğŸŒ Multi-language** support (English summaries)
- **ğŸ“ˆ Advanced Analytics** and search insights

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

1. **Data Quality**: Better text preprocessing
2. **Embedding Models**: Test domain-specific models
3. **Chunking Strategy**: Smarter document segmentation  
4. **Performance**: Optimize search speed
5. **Features**: Additional metadata extraction

## ğŸ“„ License

This project is for educational and research purposes. Legal document usage should comply with Turkish legal framework and copyright requirements.

## ğŸ†˜ Troubleshooting

### Common Issues

**Database not found:**
```bash
python build_vector_database.py
```

**Import errors:**
```bash
pip install -r requirements_rag.txt
```

**Slow embedding generation:**
- Use smaller embedding model
- Reduce batch size
- Consider TF-IDF for faster setup

**Memory issues:**
- Process data in smaller batches
- Use TF-IDF instead of neural embeddings
- Increase swap space

### Performance Tips

1. **SSD Storage**: Store database on SSD for faster access
2. **RAM**: 8GB+ recommended for large embedding models
3. **Batch Size**: Adjust based on available memory
4. **Indexing**: Database automatically creates search indexes

## ğŸ“ Support

For questions and support:
- Check the troubleshooting section
- Review example usage in `query_legal_rag.py`
- Test with simple queries first

---

ğŸ›ï¸ **Built for Turkish Legal Research & Analysis**